---
title: Vercel
description: Integrate vectorstores with Vercel's AI SDK
---

This guide demonstrates how to integrate vectorstores with Vercel's AI SDK. The `@vectorstores/vercel` package provides two key utilities:

- **`vercelEmbedding`**: Use any Vercel AI SDK embedding model with vectorstores
- **`vercelTool`**: Wrap a vectorstores retriever as a Vercel AI SDK tool for agentic workflows

## Installation

```bash
npm install @vectorstores/vercel @vectorstores/core ai
```

## Using vercelEmbedding

The `vercelEmbedding` function wraps any Vercel AI SDK embedding model to make it compatible with vectorstores:

```typescript
import { openai } from "@ai-sdk/openai";
import { Document, VectorStoreIndex } from "@vectorstores/core";
import { vercelEmbedding } from "@vectorstores/vercel";

// Create a vector index using Vercel AI SDK embeddings
const index = await VectorStoreIndex.fromDocuments(documents, {
  embedFunc: vercelEmbedding(openai.embedding("text-embedding-3-small")),
});

// Query the index
const retriever = index.asRetriever();
const results = await retriever.retrieve({ query: "What is AI?" });
```

This works with any Vercel AI SDK compatible embedding provider (OpenAI, Cohere, etc.).

## Using vercelTool

The `vercelTool` function creates a Vercel AI SDK tool from a vectorstores retriever, enabling agentic RAG workflows:

```typescript
import { openai } from "@ai-sdk/openai";
import { streamText, stepCountIs } from "ai";
import { vercelEmbedding, vercelTool } from "@vectorstores/vercel";

// Create index and retriever
const index = await VectorStoreIndex.fromDocuments(documents, {
  embedFunc: vercelEmbedding(openai.embedding("text-embedding-3-small")),
});
const retriever = index.asRetriever();

// Use the retriever as a tool in streamText
const result = streamText({
  model: openai.chat("gpt-4o-mini"),
  prompt: "What are the key concepts in AI?",
  tools: {
    queryKnowledge: vercelTool({
      retriever,
      description: "Search the AI knowledge base for information.",
    }),
  },
  stopWhen: stepCountIs(5),
});

for await (const textPart of result.textStream) {
  process.stdout.write(textPart);
}
```

### vercelTool Options

| Option | Type | Required | Description |
|--------|------|----------|-------------|
| `retriever` | `BaseRetriever` | Yes | The vectorstores retriever to wrap |
| `description` | `string` | Yes | Description for the LLM to understand when to use the tool |
| `noResultsMessage` | `string` | No | Message returned when no results are found (default: "No results found in documents.") |

## Complete Agentic RAG Example

Here's a complete example combining both utilities:

```typescript
import { openai } from "@ai-sdk/openai";
import { Document, VectorStoreIndex } from "@vectorstores/core";
import { vercelEmbedding, vercelTool } from "@vectorstores/vercel";
import { stepCountIs, streamText } from "ai";
import fs from "node:fs/promises";

async function main() {
  // Load document
  const essay = await fs.readFile("./data/essay.txt", "utf-8");
  const document = new Document({ text: essay, id_: "essay" });

  // Create index with Vercel AI SDK embeddings
  const index = await VectorStoreIndex.fromDocuments([document], {
    embedFunc: vercelEmbedding(openai.embedding("text-embedding-3-small")),
  });

  // Create retriever and wrap as tool
  const retriever = index.asRetriever();

  // Stream response with agentic tool calling
  const result = streamText({
    model: openai.chat("gpt-4o-mini"),
    prompt: "Summarize the key points from the essay.",
    tools: {
      queryKnowledge: vercelTool({
        retriever,
        description: "Search the essay for relevant information.",
      }),
    },
    stopWhen: stepCountIs(5),
  });

  for await (const textPart of result.textStream) {
    process.stdout.write(textPart);
  }
}

main().catch(console.error);
```

## Manual Integration (Alternative)

If you prefer manual integration without the `@vectorstores/vercel` package, you can use the core utilities directly:

```typescript
import { openai } from "@ai-sdk/openai";
import { Document, formatLLM, Settings, VectorStoreIndex } from "@vectorstores/core";
import { stepCountIs, streamText, tool, embedMany } from "ai";
import { z } from "zod";

// Configure embeddings manually
Settings.embedFunc = async (input) => {
  const { embeddings } = await embedMany({
    model: openai.embedding("text-embedding-3-small"),
    values: input,
  });
  return embeddings;
};

const index = await VectorStoreIndex.fromDocuments([document]);
const retriever = index.asRetriever();

// Create tool manually
const result = streamText({
  model: openai.chat("gpt-4o-mini"),
  prompt: "Your question here",
  tools: {
    queryTool: tool({
      description: "Search the knowledge base.",
      parameters: z.object({
        query: z.string().describe("The search query."),
      }),
      execute: async ({ query }) => {
        return formatLLM(await retriever.retrieve({ query })) || "No results found";
      },
    }),
  },
  stopWhen: stepCountIs(5),
});
```

## How It Works

1. The LLM receives the user's question
2. It decides whether to use the tool to search the knowledge base
3. If it calls the tool, the retriever searches the indexed documents
4. The retrieved information is formatted and returned to the LLM
5. The LLM uses this information to generate a response
6. The process can repeat for multi-step reasoning (up to 5 steps)
7. The final response is streamed to the user

## Key Benefits

- **Simple Integration**: `vercelEmbedding` and `vercelTool` provide one-line integrations
- **Provider Agnostic**: Works with any Vercel AI SDK compatible provider
- **Autonomous Information Retrieval**: The LLM decides when to query the knowledge base
- **Multi-step Reasoning**: Can perform multiple queries to gather comprehensive information
- **Streaming Responses**: Provides real-time feedback to users

## Next Steps

1. Experiment with different retrieval strategies and tool configurations
2. Try using different Vercel AI [model providers](https://sdk.vercel.ai/docs/foundations/providers-and-models)
3. Combine with other vectorstores features like reranking for improved accuracy
